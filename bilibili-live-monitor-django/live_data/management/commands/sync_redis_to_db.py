from django.core.management.base import BaseCommand
from django.utils import timezone
from django.db import transaction
from live_data.models import LiveRoom, DanmakuData, GiftData, DataMigrationLog
from utils.redis_handler import get_redis_client
import json
import logging
from decimal import Decimal
from datetime import datetime

logger = logging.getLogger(__name__)

class Command(BaseCommand):
    help = 'å°†Redisä¸­çš„æ•°æ®åŒæ­¥åˆ°SQLiteæ•°æ®åº“'
    
    def add_arguments(self, parser):
        parser.add_argument(
            '--room-id',
            type=int,
            help='æŒ‡å®šæˆ¿é—´IDï¼Œä¸æŒ‡å®šåˆ™åŒæ­¥æ‰€æœ‰æˆ¿é—´'
        )
        parser.add_argument(
            '--data-type',
            choices=['danmaku', 'gift', 'all'],
            default='all',
            help='æŒ‡å®šæ•°æ®ç±»å‹'
        )
        parser.add_argument(
            '--batch-size',
            type=int,
            default=100,
            help='æ‰¹å¤„ç†å¤§å°'
        )
        parser.add_argument(
            '--dry-run',
            action='store_true',
            help='è¯•è¿è¡Œï¼Œä¸å®é™…å†™å…¥æ•°æ®åº“'
        )
    
    def handle(self, *args, **options):
        self.redis_client = get_redis_client()
        self.batch_size = options['batch_size']
        self.dry_run = options['dry_run']
        
        if self.dry_run:
            self.stdout.write("ğŸ” è¯•è¿è¡Œæ¨¡å¼ - ä¸ä¼šå®é™…å†™å…¥æ•°æ®")
        
        # åˆ›å»ºè¿ç§»æ—¥å¿—
        migration_log = DataMigrationLog.objects.create(
            migration_type=options['data_type'],
            start_time=timezone.now(),
            status='running'
        )
        
        try:
            if options['room_id']:
                rooms = [options['room_id']]
            else:
                rooms = self.get_all_monitored_rooms()
            
            total_synced = 0
            
            for room_id in rooms:
                self.stdout.write(f"ğŸ“¡ åŒæ­¥æˆ¿é—´ {room_id} çš„æ•°æ®...")
                
                if options['data_type'] in ['danmaku', 'all']:
                    count = self.sync_danmaku_data(room_id)
                    total_synced += count
                    self.stdout.write(f"  âœ… å¼¹å¹•: {count} æ¡")
                
                if options['data_type'] in ['gift', 'all']:
                    count = self.sync_gift_data(room_id)
                    total_synced += count
                    self.stdout.write(f"  âœ… ç¤¼ç‰©: {count} æ¡")
            
            # æ›´æ–°è¿ç§»æ—¥å¿—
            migration_log.end_time = timezone.now()
            migration_log.total_records = total_synced
            migration_log.success_records = total_synced
            migration_log.status = 'completed'
            migration_log.save()
            
            self.stdout.write(
                self.style.SUCCESS(f'ğŸ‰ åŒæ­¥å®Œæˆï¼æ€»è®¡å¤„ç† {total_synced} æ¡æ•°æ®')
            )
            
        except Exception as e:
            # æ›´æ–°è¿ç§»æ—¥å¿—
            migration_log.end_time = timezone.now()
            migration_log.status = 'failed'
            migration_log.error_message = str(e)
            migration_log.save()
            
            self.stdout.write(
                self.style.ERROR(f'âŒ åŒæ­¥å¤±è´¥: {e}')
            )
            raise
    
    def get_all_monitored_rooms(self):
        """è·å–æ‰€æœ‰è¢«ç›‘æ§çš„æˆ¿é—´ID"""
        pattern = "room:*:danmaku"
        keys = self.redis_client.keys(pattern)
        
        room_ids = []
        for key in keys:
            try:
                # ä» "room:123456:danmaku" ä¸­æå–æˆ¿é—´ID
                room_id = int(key.decode('utf-8').split(':')[1])
                room_ids.append(room_id)
            except (ValueError, IndexError):
                continue
        
        return list(set(room_ids))  # å»é‡
    
    def sync_danmaku_data(self, room_id):
        """åŒæ­¥å¼¹å¹•æ•°æ®"""
        redis_key = f"room:{room_id}:danmaku"
        
        # è·å–Redisä¸­çš„å¼¹å¹•æ•°æ®
        danmaku_list = self.redis_client.lrange(redis_key, 0, -1)
        
        if not danmaku_list:
            return 0
        
        # ç¡®ä¿æˆ¿é—´å­˜åœ¨
        room, created = LiveRoom.objects.get_or_create(
            room_id=room_id,
            defaults={
                'title': f'æˆ¿é—´ {room_id}',
                'uname': 'æœªçŸ¥ä¸»æ’­'
            }
        )
        
        synced_count = 0
        batch_data = []
        
        for danmaku_json in danmaku_list:
            try:
                danmaku_data = json.loads(danmaku_json)
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆé¿å…é‡å¤ï¼‰
                timestamp = datetime.fromtimestamp(danmaku_data.get('timestamp', 0))
                timestamp = timezone.make_aware(timestamp)
                
                exists = DanmakuData.objects.filter(
                    room=room,
                    uid=danmaku_data.get('uid', 0),
                    message=danmaku_data.get('message', ''),
                    timestamp=timestamp
                ).exists()
                
                if exists:
                    continue
                
                # å‡†å¤‡æ•°æ®
                danmaku_obj = DanmakuData(
                    room=room,
                    uid=danmaku_data.get('uid', 0),
                    username=danmaku_data.get('username', 'åŒ¿åç”¨æˆ·'),
                    message=danmaku_data.get('message', ''),
                    timestamp=timestamp,
                    medal_name=danmaku_data.get('medal_name', ''),
                    medal_level=danmaku_data.get('medal_level', 0),
                    user_level=danmaku_data.get('user_level', 0),
                    is_admin=danmaku_data.get('is_admin', False),
                    is_vip=danmaku_data.get('is_vip', False)
                )
                
                batch_data.append(danmaku_obj)
                
                # æ‰¹é‡æ’å…¥
                if len(batch_data) >= self.batch_size:
                    if not self.dry_run:
                        with transaction.atomic():
                            DanmakuData.objects.bulk_create(batch_data, ignore_conflicts=True)
                    synced_count += len(batch_data)
                    batch_data = []
                    
            except (json.JSONDecodeError, ValueError, KeyError) as e:
                logger.warning(f"è§£æå¼¹å¹•æ•°æ®å¤±è´¥: {e}")
                continue
        
        # å¤„ç†å‰©ä½™æ•°æ®
        if batch_data:
            if not self.dry_run:
                with transaction.atomic():
                    DanmakuData.objects.bulk_create(batch_data, ignore_conflicts=True)
            synced_count += len(batch_data)
        
        return synced_count
    
    def sync_gift_data(self, room_id):
        """åŒæ­¥ç¤¼ç‰©æ•°æ®"""
        redis_key = f"room:{room_id}:gifts"
        
        # è·å–Redisä¸­çš„ç¤¼ç‰©æ•°æ®
        gift_list = self.redis_client.lrange(redis_key, 0, -1)
        
        if not gift_list:
            return 0
        
        # ç¡®ä¿æˆ¿é—´å­˜åœ¨
        room, created = LiveRoom.objects.get_or_create(
            room_id=room_id,
            defaults={
                'title': f'æˆ¿é—´ {room_id}',
                'uname': 'æœªçŸ¥ä¸»æ’­'
            }
        )
        
        synced_count = 0
        batch_data = []
        
        for gift_json in gift_list:
            try:
                gift_data = json.loads(gift_json)
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆé¿å…é‡å¤ï¼‰
                timestamp = datetime.fromtimestamp(gift_data.get('timestamp', 0))
                timestamp = timezone.make_aware(timestamp)
                
                exists = GiftData.objects.filter(
                    room=room,
                    uid=gift_data.get('uid', 0),
                    gift_id=gift_data.get('gift_id', 0),
                    timestamp=timestamp
                ).exists()
                
                if exists:
                    continue
                
                # å‡†å¤‡æ•°æ®
                price = Decimal(str(gift_data.get('price', 0)))
                num = gift_data.get('num', 1)
                total_price = price * num
                
                gift_obj = GiftData(
                    room=room,
                    uid=gift_data.get('uid', 0),
                    username=gift_data.get('username', 'åŒ¿åç”¨æˆ·'),
                    gift_name=gift_data.get('gift_name', 'æœªçŸ¥ç¤¼ç‰©'),
                    gift_id=gift_data.get('gift_id', 0),
                    num=num,
                    price=price,
                    total_price=total_price,
                    timestamp=timestamp,
                    medal_name=gift_data.get('medal_name', ''),
                    medal_level=gift_data.get('medal_level', 0)
                )
                
                batch_data.append(gift_obj)
                
                # æ‰¹é‡æ’å…¥
                if len(batch_data) >= self.batch_size:
                    if not self.dry_run:
                        with transaction.atomic():
                            GiftData.objects.bulk_create(batch_data, ignore_conflicts=True)
                    synced_count += len(batch_data)
                    batch_data = []
                    
            except (json.JSONDecodeError, ValueError, KeyError) as e:
                logger.warning(f"è§£æç¤¼ç‰©æ•°æ®å¤±è´¥: {e}")
                continue
        
        # å¤„ç†å‰©ä½™æ•°æ®
        if batch_data:
            if not self.dry_run:
                with transaction.atomic():
                    GiftData.objects.bulk_create(batch_data, ignore_conflicts=True)
            synced_count += len(batch_data)
        
        return synced_count